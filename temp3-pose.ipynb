{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "True\n"
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tool\n",
    "import pylab\n",
    "import os\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "pylab.rcParams['figure.figsize'] = (15.0,7.0) #调整显示大小\n",
    "tool.setGrid(1,2)\n",
    "\n",
    "print(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "run program\n180000.0\n(640, 480)\nin producer\nloaded file from ./doc/temp3-calibrate-2020-06-16 214523.npz \n 0.47564462385356643 \n [[518.92730713   0.         316.5496548 ]\n [  0.         485.13198853 239.77230672]\n [  0.           0.           1.        ]] [1 1 6 6]\ncorners flase\n***** (49, 3) (42, 1, 2) (3, 3) (1, 5)\nend\n"
    },
    {
     "output_type": "error",
     "ename": "error",
     "evalue": "OpenCV(4.0.1) C:\\ci\\opencv-suite_1573470242804\\work\\modules\\calib3d\\src\\solvepnp.cpp:92: error: (-215:Assertion failed) ( (npoints >= 4) || (npoints == 3 && flags == SOLVEPNP_ITERATIVE && useExtrinsicGuess) ) && npoints == std::max(ipoints.checkVector(2, CV_32F), ipoints.checkVector(2, CV_64F)) in function 'cv::solvePnP'\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-fe94d144b7a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    225\u001b[0m     \u001b[1;31m# producer = Producer(rtmp_str,init=init,ring=ring)  # 开个线程\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m     \u001b[0mproducer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mProducer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrtmp_str\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'load'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mring\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 开个线程\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 227\u001b[1;33m     \u001b[0mproducer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-fe94d144b7a8>\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-fe94d144b7a8>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     57\u001b[0m                 \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m                 \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m                 \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dis'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;31m# except Exception as e:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-fe94d144b7a8>\u001b[0m in \u001b[0;36mring\u001b[1;34m(state, key, image)\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'pnp'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'pnp'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m         \u001b[0mfc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolvePnP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m         \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"none\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-fe94d144b7a8>\u001b[0m in \u001b[0;36msolvePnP\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m    164\u001b[0m             \u001b[1;31m# print(\"*****\",self.objp, corners2, self.mtx, self.dist)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"*****\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorners2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmtx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m             \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrvecs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtvecs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolvePnP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorners2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m             \u001b[1;31m# ret,rvecs, tvecs = cv.solvePnPRansac(self.objp, corners2, self.mtx, self.dist)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m             \u001b[1;31m# project 3D points to image plane\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.0.1) C:\\ci\\opencv-suite_1573470242804\\work\\modules\\calib3d\\src\\solvepnp.cpp:92: error: (-215:Assertion failed) ( (npoints >= 4) || (npoints == 3 && flags == SOLVEPNP_ITERATIVE && useExtrinsicGuess) ) && npoints == std::max(ipoints.checkVector(2, CV_32F), ipoints.checkVector(2, CV_64F)) in function 'cv::solvePnP'\n"
     ]
    }
   ],
   "source": [
    "# https://www.cnblogs.com/sirxy/p/12126383.html\n",
    "\n",
    "import threading\n",
    "\n",
    "\n",
    "class DummyThread:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def start(self):\n",
    "        self.run()\n",
    "        \n",
    "\n",
    "# class Producer(threading.Thread):\n",
    "class Producer(DummyThread):\n",
    "    \"\"\"docstring for Producer\"\"\"\n",
    "    def __init__(self, rtmp_str,state='none',apiPreference =cv.CAP_ANY,init=None,ring=None):\n",
    "        super(Producer, self).__init__()\n",
    "        self.rtmp_str = rtmp_str\n",
    "        # 通过cv中的类获取视频流操作对象cap\n",
    "        self.cap = cv.VideoCapture(self.rtmp_str,apiPreference)\n",
    "        # 调用cv方法获取cap的视频帧（帧：每秒多少张图片）\n",
    "        # fps = self.cap.get(cv.CAP_PROP_FPS)\n",
    "        self.fps = self.cap.get(cv.CAP_PROP_FPS)\n",
    "        print(self.fps)\n",
    "        # 获取cap视频流的每帧大小\n",
    "        self.width = int(self.cap.get(cv.CAP_PROP_FRAME_WIDTH))\n",
    "        self.height = int(self.cap.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
    "        \n",
    "        self.size = (self.width, self.height)\n",
    "        print(self.size)\n",
    "#         定义编码格式mpge-4\n",
    "        # self.fourcc = cv.VideoWriter_fourcc('M', 'P', '4', '2')\n",
    "        # 定义视频文件输入对象\n",
    "#         self.outVideo = cv.VideoWriter('./tempdoc/saveDir1.avi', self.fourcc, self.fps, self.size)\n",
    "\n",
    "        self.state = state\n",
    "        self.ring=ring\n",
    "        if(init):\n",
    "            init(self)\n",
    "    def run(self):\n",
    "        print('in producer')\n",
    "        try:\n",
    "            ret, image = self.cap.read()\n",
    "            while ret:\n",
    "    #             self.outVideo.write(image)\n",
    "                # image = cv.pyrDown(image)\n",
    "                \n",
    "                wait = int(1000 / int(self.fps))\n",
    "                wait = max(min(wait,300),20)\n",
    "                key = cv.waitKey(wait)  # 延迟\n",
    "                if key & 0xFF ==27:#  == ord('q'):#\n",
    "                    print('break')\n",
    "    # #                 self.outVideo.release()\n",
    "    #                 self.cap.release()\n",
    "    #                 cv.destroyAllWindows()\n",
    "                    break\n",
    "                ret, image = self.cap.read()\n",
    "                if(self.ring):\n",
    "                    self.state,image = self.ring(self.state,key,image)\n",
    "                cv.imshow('dis', image)\n",
    "        # except Exception as e:\n",
    "        #     print(\"error\",repr(e))\n",
    "        finally:\n",
    "            print('end')\n",
    "    #         self.outVideo.release()\n",
    "            self.cap.release()\n",
    "            cv.destroyAllWindows()\n",
    "        \n",
    "\n",
    "class FindCorners():\n",
    "    def __init__(self,shape):\n",
    "        self.findCnt= 0\n",
    "        self.objpoints=[]\n",
    "        self.imgpoints=[]\n",
    "        self.lastCornersRet = False\n",
    "        self.lastCorners = None\n",
    "        self.shape = shape\n",
    "        self.objp = np.zeros((self.shape[0]*self.shape[1],3), np.float32)\n",
    "        self.objp[:,:2] = np.mgrid[0:self.shape[0],0:self.shape[1]].T.reshape(-1,2)\n",
    "        self.criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "        self.imgShape = None\n",
    "        \n",
    "        self.ret, self.mtx, self.dist, self.rvecs, self.tvecs = 0,None,None,None,None,\n",
    "        self.newcameramtx, self.roi = None,None\n",
    "    def load(self,file):\n",
    "        load = np.load(file)\n",
    "        # print(dir(load),load.files)\n",
    "\n",
    "        self.ret = load['arr_0']\n",
    "        self.mtx = load['arr_1']\n",
    "        self.dist = load['arr_2']\n",
    "        self.rvecs = load['arr_3']\n",
    "        self.tvecs = load['arr_4']\n",
    "        self.newcameramtx = load['arr_5']\n",
    "        self.roi = load['arr_6']\n",
    "        print(\"loaded file from\",file,'\\n', self.ret,'\\n',self.newcameramtx,self.roi)\n",
    "    def save(self,file=''):\n",
    "        if(not file):\n",
    "            file = './doc/temp3-calibrate-'+time.strftime(\"%Y-%m-%d %H%M%S\", time.localtime())\n",
    "        np.savez(file,\n",
    "            self.ret, self.mtx, self.dist, self.rvecs, self.tvecs,\n",
    "            self.newcameramtx, self.roi)\n",
    "        print('saved para to',file)\n",
    "    def find(self,img):\n",
    "        gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "        self.imgShape= gray.shape[::-1]\n",
    "        self.lastCornersRet, self.lastCorners = cv.findChessboardCorners(gray, self.shape, None)\n",
    "        self.findCnt+=1\n",
    "        if(self.lastCornersRet):\n",
    "            self.objpoints.append(self.objp)\n",
    "            corners2 = cv.cornerSubPix(gray,self.lastCorners, (11,11), (-1,-1), self.criteria)\n",
    "            self.imgpoints.append(corners2)\n",
    "        print(\"state: find:%d finded:%d fail:%d\"%(self.findCnt,len(self.imgpoints),self.findCnt-len(self.imgpoints)),\n",
    "            end='\\r\\r\\r')\n",
    "        return self.lastCornersRet, self.lastCorners\n",
    "        # cv.drawChessboardCorners(det, self.shape, corners2, ret)\n",
    "        # cv.imshow('finded', det)\n",
    "    def drawChessboardCornersLast(self,img):\n",
    "#         if(self.lastCornersRet):\n",
    "        cv.drawChessboardCorners(img, self.shape, self.lastCorners,  self.lastCornersRet)\n",
    "\n",
    "    def calibrate(self):\n",
    "        if(len(self.imgpoints)):\n",
    "            self.ret, self.mtx, self.dist, self.rvecs, self.tvecs = \\\n",
    "                cv.calibrateCamera(self.objpoints, self.imgpoints, self.imgShape, None, None)\n",
    "            self.newcameramtx, self.roi = \\\n",
    "                cv.getOptimalNewCameraMatrix(self.mtx, self.dist, self.shape, 1,self.shape)\n",
    "        else:\n",
    "            self.ret, self.mtx, self.dist, self.rvecs, self.tvecs = 0,None,None,None,None,\n",
    "            self.newcameramtx, self.roi = None,None\n",
    "        return self.ret,self.newcameramtx, self.roi\n",
    "    def undistort(self,img):\n",
    "        # print(self.roi, self.roi and self.roi[2] , self.roi and self.roi[3])\n",
    "        if(self.roi.any() and self.roi[2] and self.roi[3]):\n",
    "            return cv.undistort(img, self.mtx, self.dist, None, self.newcameramtx)\n",
    "        else:\n",
    "            return np.full_like(img,180)\n",
    "\n",
    "    def draw(self, img, corners, imgpts):\n",
    "        corner = tuple(corners[0].ravel())\n",
    "        img = cv.line(img, corner, tuple(imgpts[0].ravel()), (255,0,0), 5)\n",
    "        img = cv.line(img, corner, tuple(imgpts[1].ravel()), (0,255,0), 5)\n",
    "        img = cv.line(img, corner, tuple(imgpts[2].ravel()), (0,0,255), 5)\n",
    "        return img\n",
    "    def drawCube(self, img, corners, imgpts):\n",
    "        imgpts = np.int32(imgpts).reshape(-1,2)\n",
    "        # draw ground floor in green\n",
    "        img = cv.drawContours(img, [imgpts[:4]],-1,(0,255,0),-3)\n",
    "        # draw pillars in blue color\n",
    "        for i,j in zip(range(4),range(4,8)):\n",
    "            img = cv.line(img, tuple(imgpts[i]), tuple(imgpts[j]),(255),3)\n",
    "        # draw top layer in red color\n",
    "        img = cv.drawContours(img, [imgpts[4:]],-1,(0,0,255),3)\n",
    "        return img\n",
    "    def solvePnP(self,img):\n",
    "        gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "        ret, corners = cv.findChessboardCorners(gray, (7,6),None)\n",
    "        if ret == True:\n",
    "            axis = np.float32([[3,0,0], [0,3,0], [0,0,-3]]).reshape(-1,3)\n",
    "            criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "            corners2 = cv.cornerSubPix(gray,corners,(11,11),(-1,-1),criteria)#self.criteria)\n",
    "            # print(\"****\",corners2.reshape((len(corners2),2)))\n",
    "            # Find the rotation and translation vectors.\n",
    "            # print(\"*****\",self.objp, corners2, self.mtx, self.dist)\n",
    "            print(\"*****\",self.objp.shape, corners2.shape, self.mtx.shape, self.dist.shape)\n",
    "            ret,rvecs, tvecs = cv.solvePnP(self.objp, corners2, self.mtx, self.dist)\n",
    "            # ret,rvecs, tvecs = cv.solvePnPRansac(self.objp, corners2, self.mtx, self.dist)\n",
    "            # project 3D points to image plane\n",
    "            imgpts, jac = cv.projectPoints(axis, rvecs, tvecs, self.mtx, self.dist)\n",
    "            img = self.draw(img,corners2,imgpts)\n",
    "            print(img.shape)\n",
    "            cv.imshow('pnp',img)\n",
    "        else:\n",
    "            print(\"corners flase\",end=\"\\n\")\n",
    "           \n",
    "\n",
    "fc =None\n",
    "\n",
    "def init(pd):\n",
    "    global fc #(pd.width,pd.height)\n",
    "    fc=FindCorners((7,7))\n",
    "\n",
    "def ring(state,key,image):\n",
    "    global fc\n",
    "    # print(state, key, end=\"\\r\")\n",
    "    if(state==\"load\"):\n",
    "        file = \"./doc/temp3-calibrate-2020-06-16 214523.npz\"\n",
    "        fc.load(file)\n",
    "        state = 'calibrated'\n",
    "        # np.savez,np.savetxt\n",
    "    if (key & 0xFF ==ord('f')) and  (state == 'none'):\n",
    "        print(\"type(fc.find)\")\n",
    "        # print(type(fc.find))\n",
    "        ret,corners = fc.find(image)\n",
    "        if(ret):\n",
    "            state = 'finded'\n",
    "        finded = image.copy()\n",
    "        fc.drawChessboardCornersLast(finded)\n",
    "        cv.imshow('finded', finded)\n",
    "    elif state == 'finded':\n",
    "        state = 'none'\n",
    "    \n",
    "    if (key == ord('c')) and (state == 'none'):\n",
    "        print('\\n')\n",
    "        ret,cameramtx,roi = fc.calibrate()\n",
    "        print(ret,'\\n',type(ret),cameramtx,roi,type(roi[3]))\n",
    "        fc.save()\n",
    "        state = 'calibrated'\n",
    "\n",
    "    if(state == 'calibrated'):\n",
    "        image = fc.undistort(image)\n",
    "\n",
    "\n",
    "    if(key == ord('p')):\n",
    "        state = 'pnp'\n",
    "    if(state == 'pnp'):\n",
    "        fc.solvePnP(image)\n",
    "        state = \"none\"\n",
    "    return state,image\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print('run program')\n",
    "    rtmp_str = 'rtsp://admin:admin@192.168.1.154:8554/live'  # ip摄像头 #帧率不太对\n",
    "    # rtmp_str = 'rtsp://admin:admin@192.168.31.60:8554/live'  # ip摄像头 #帧率不太对\n",
    "    # producer = Producer(rtmp_str,init=init,ring=ring)  # 开个线程\n",
    "    producer = Producer(rtmp_str,'load',init=init,ring=ring)  # 开个线程\n",
    "    producer.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "True\n4.0.1\n"
    }
   ],
   "source": [
    "print(bool([1,2,3]))\n",
    "print(cv.__version__)\n",
    "# print((,2))\n",
    "# ?cv.solvePnP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('opencv': conda)",
   "language": "python",
   "name": "python38264bitopencvcondaf8e25ba750324c03822601bb64b1caae"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}