{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tool\n",
    "import pylab\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "pylab.rcParams['figure.figsize'] = (15.0,7.0) #调整显示大小\n",
    "tool.setGrid(1,2)\n",
    "\n",
    "class Detection:\n",
    "    def __init__(self,xml,color):\n",
    "        self.xml = xml\n",
    "        self.color = color\n",
    "        self.facesCascadc = cv.CascadeClassifier(xml)\n",
    "    def haar_execute(self,gray):\n",
    "        blocks = self.facesCascadc.detectMultiScale(\n",
    "            gray,\n",
    "            scaleFactor = 1.15,\n",
    "            minNeighbors = 5,\n",
    "            minSize = (5,5)\n",
    "        )\n",
    "        self.blocks = blocks\n",
    "        return blocks\n",
    "    def draw_blocks(self,src,copy=False):\n",
    "        dis = src\n",
    "        if(copy):\n",
    "            dis = np.array(src)\n",
    "        for (x,y,w,h) in self.blocks:\n",
    "            cv.rectangle(dis,(x,y),(x+w,y+h),self.color,2)\n",
    "        return dis\n",
    "\n",
    "# https://github.com/opencv/opencv/tree/master/data/haarcascades\n",
    "# faceDet = Detection('./tempdoc/haarcascade_profileface.xml',(255,50,50))\n",
    "faceDet = Detection('./tempdoc/haarcascade_frontalface_default.xml',(255,150,150))\n",
    "eyeDet = Detection('./tempdoc/haarcascade_eye.xml',(155,150,250))\n",
    "# leyeDet = Detection('./tempdoc/haarcascade_lefteye_2splits.xml',(155,250,250))\n",
    "# reyeDet = Detection('./tempdoc/haarcascade_righteye_2splits.xml',(255,150,250))\n",
    "# smileDet = Detection('./tempdoc/haarcascade_smile.xml',(50,50,250))\n",
    "\n",
    "def detAdd2Img(frame):\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    faceDet.haar_execute(gray)\n",
    "    dis = faceDet.draw_blocks(frame)\n",
    "    eyeDet.haar_execute(gray)\n",
    "    dis = eyeDet.draw_blocks(dis)\n",
    "#     leyeDet.haar_execute(gray)\n",
    "#     dis = leyeDet.draw_blocks(dis)\n",
    "#     reyeDet.haar_execute(gray)\n",
    "#     dis = reyeDet.draw_blocks(dis)\n",
    "#     smileDet.haar_execute(gray)\n",
    "#     dis = smileDet.draw_blocks(dis)\n",
    "#     cv.imshow('frame',frame)\n",
    "#     cv.imshow('gray',gray)\n",
    "    return dis\n",
    "\n",
    "print(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cap = cv.VideoCapture(0)\n",
    "print(cap.isOpened())\n",
    "while(cap.isOpened()):\n",
    "    ret,frame = cap.read()\n",
    "    \n",
    "    dis = detAdd2Img(frame)\n",
    "    cv.imshow('dis',dis)\n",
    "    c = cv.waitKey(1)\n",
    "    if c==27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run program\n",
      "rtsp_transport;udp\n",
      "0.0\n",
      "(0, 0)\n",
      "in producer\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "# https://www.cnblogs.com/sirxy/p/12126383.html\n",
    "\n",
    "import cv2\n",
    "import threading\n",
    "\n",
    "class Producer(threading.Thread):\n",
    "    \"\"\"docstring for Producer\"\"\"\n",
    "    def __init__(self, rtmp_str,apiPreference =cv.CAP_ANY):\n",
    "        super(Producer, self).__init__()\n",
    "        self.rtmp_str = rtmp_str\n",
    "        # 通过cv2中的类获取视频流操作对象cap\n",
    "        self.cap = cv2.VideoCapture(self.rtmp_str,apiPreference)\n",
    "        # 调用cv2方法获取cap的视频帧（帧：每秒多少张图片）\n",
    "        # fps = self.cap.get(cv2.CAP_PROP_FPS)\n",
    "        self.fps = self.cap.get(cv2.CAP_PROP_FPS)\n",
    "        print(self.fps)\n",
    "        # 获取cap视频流的每帧大小\n",
    "        self.width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        self.height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        \n",
    "        self.size = (self.width, self.height)\n",
    "        print(self.size)\n",
    "#         定义编码格式mpge-4\n",
    "        self.fourcc = cv2.VideoWriter_fourcc('M', 'P', '4', '2')\n",
    "        # 定义视频文件输入对象\n",
    "#         self.outVideo = cv2.VideoWriter('./tempdoc/saveDir1.avi', self.fourcc, self.fps, self.size)\n",
    "    def run(self):\n",
    "        print('in producer')\n",
    "        ret, image = self.cap.read()\n",
    "        while ret:\n",
    "            # if ret == True:\n",
    "#             self.outVideo.write(image)\n",
    "#             cv2.imshow('video', image)\n",
    "            \n",
    "            image = cv.pyrDown(image)\n",
    "            dis = detAdd2Img(image)\n",
    "            cv2.imshow('dis', dis)\n",
    "            \n",
    "            wait = int(1000 / int(self.fps))\n",
    "            wait = max(min(wait,300),20)\n",
    "            key = cv2.waitKey(wait)  # 延迟\n",
    "            if key & 0xFF ==27:#  == ord('q'):#\n",
    "# #                 self.outVideo.release()\n",
    "#                 self.cap.release()\n",
    "#                 cv2.destroyAllWindows()\n",
    "                break\n",
    "            ret, image = self.cap.read()\n",
    "        print('end')\n",
    "#         self.outVideo.release()\n",
    "        self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print('run program')\n",
    "    # rtmp_str = 'rtmp://live.hkstv.hk.lxdns.com/live/hks'  # 经测试，已不能用。可以尝试下面两个。\n",
    "    # rtmp_str = 'rtmp://media3.scctv.net/live/scctv_800'  # CCTV\n",
    "    rtmp_str = 'rtmp://58.200.131.2:1935/livetv/hunantv'  # 湖南卫视\n",
    "#     rtmp_str='http://liveplay-kk.rtxapp.com/live/program/live/hnwshd/2300000/mnf.m3u8' #湖南卫视\n",
    "#     rtmp_str='http://live-temp-litchi-hls-yf.jstv.com/live/zhibo-cctv13/online.m3u8' #央视新闻\n",
    "#     rtmp_str='http://ali.m.l.cztv.com/channels/lantian/channel01/360p.m3u8' #浙江卫视\n",
    "#     rtmp_str='http://liveplay-kk.rtxapp.com/live/program/live/cctv1hd/4000000/mnf.m3u8' #央视综合\n",
    "#     rtmp_str = 'rtsp://admin:admin@192.168.31.60:8554/live'  # ip摄像头 #帧率不太对\n",
    "    producer = Producer(rtmp_str)  # 开个线程\n",
    "    producer.start()\n",
    "\n",
    "##########################################\n",
    "### 这个方法应该在linux下有效吧\\n\",\n",
    "# 参考\n",
    "# https://stackoverflow.com/questions/43047017/opencv-rtsp-stream-protocol\n",
    "# https://github.com/opencv/opencv/pull/9292\n",
    "\n",
    "# #     print(os.environ[\"OPENCV_FFMPEG_CAPTURE_OPTIONS\"])\n",
    "#     os.environ[\"OPENCV_FFMPEG_CAPTURE_OPTIONS\"] = \"rtsp_transport;udp\"\n",
    "#     print(os.environ[\"OPENCV_FFMPEG_CAPTURE_OPTIONS\"])\n",
    "#     rtmp_str = 'rtsp://192.168.31.7:554/live'\n",
    "#     producer = Producer(rtmp_str,cv2.CAP_FFMPEG)\n",
    "#     producer.start()\n",
    "\n",
    "#     tool.put_list(os.environ.keys())\n",
    "#     ?os.environ\n",
    "#     !ffmpeg\n",
    "########################################\n",
    "\n",
    "# rtsp://admin:admin@192.168.31.60:8554/live\n",
    "# http://192.168.31.60:8081\n",
    "# http://192.168.31.60:8081/video\n",
    "# http://192.168.31.60:8081/audio.opus\n",
    "# http://192.168.31.60:8081/live.flv\n",
    "# http://k3rovgaevygqx.local:8081"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda opencv",
   "language": "python",
   "name": "opencv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
